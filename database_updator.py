#! /usr/bin/env python
#  -*- coding: utf-8 -*-
#
# GUI module generated by PAGE version 4.14
# In conjunction with Tcl version 8.6
#	Aug 13, 2018 03:57:27 PM

import urllib.parse
import urllib.request
from urllib.error import HTTPError, URLError
import shutil
import os
import os.path
import sqlite3 as sql
from bs4 import BeautifulSoup
import copy



conn = None
cursor = None

def download(link, file_name):
	url = urllib.request.Request(
		link,
		data=None,
		headers={
			   'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'
		  }
		)

	with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:
		 shutil.copyfileobj(response, out_file)
		 
def insert_novel(name, url):
	global conn, cursor
	filename = "./tmp/novel_"+urllib.parse.quote(name)+".html"
	down = "https://www.novelupdates.com/series/"+name.replace("'", '').replace(" ", '-')+"/"
	try:
		download(down, filename)
	except HTTPError as e:
		# Return code error (e.g. 404, 501, ...)
		print('URL: {}, HTTPError: {} - {}'.format(down, e.code, e.reason))
		if e.code == 404: 
			print('alt mode record')
			insert_novel2(name, url)
	except URLError as e:
		# Not an HTTP-specific error (e.g. connection refused)
		print('URL: {}, URLError: {}'.format(down, e.reason))
	else:
		fileHandle = open(filename, "r", encoding = "utf8")
		soup = BeautifulSoup(fileHandle, 'html.parser')
		img = soup.find(class_='seriesimg').find('img').get('src')
		autors = ''
		dom_authors = soup.find(id='showauthors').find_all('a')
		for aut in dom_authors:
			if autors != '': autors += ', '
			autors += aut.string
		cursor.execute("INSERT INTO Information(NovelName,link,autor,cover) VALUES(?,?,?,?)", (name, url, autors, img))
		conn.commit()
		fileHandle.close();
		os.remove(filename)
		 
def insert_novel2(name, url):
	global conn, cursor
	filename = "./tmp/novel_"+urllib.parse.quote(name)+"_2.html"
	down = url
	try:
		download(down, filename)
	except HTTPError as e:
		print('URL: {}, HTTPError: {} - {}'.format(down, e.code, e.reason))
	except URLError as e:
		print('URL: {}, URLError: {}'.format(down, e.reason))
	else:
		fileHandle = open(filename, "r", encoding = "utf8")
		soup = BeautifulSoup(fileHandle, 'html.parser')
		nov = soup.find(class_='media media-novel-index')
		img = nov.find('img').get('src')
		autors = ''
		dom_authors = nov.find_all('p')
		for aut in dom_authors:
			if aut.string is not None:
				if 'Author:' in aut.string:
					if autors != '': autors += ', '
					autors += aut.string.replace('Author:', '').strip()
		cursor.execute("INSERT INTO Information(NovelName,link,autor,cover) VALUES(?,?,?,?)", (name, url, autors, img))
		conn.commit()
		fileHandle.close();
		os.remove(filename)
		 
def start():
	global conn, cursor
	conn = sql.connect("novels.db")
	cursor = conn.cursor()
	# cursor.execute("SELECT NovelName,link,autor,cover FROM 'Information'")
	# db = cursor.fetchall()
	# namelist = []
	# for i in db:
		# namelist.append(i[0])
		# namelist.sort()
	# print(namelist)
	if os.path.isdir('./tmp') is False:
		os.mkdir('./tmp')
	
	filename = "./tmp/bdd_updates.html"
	baseurl = 'https://www.wuxiaworld.com/updates'
	try:
		download(baseurl, filename)
	except HTTPError as e:
		# Return code error (e.g. 404, 501, ...)
		print('URL: {}, HTTPError: {} - {}'.format(baseurl, e.code, e.reason))
	except URLError as e:
		# Not an HTTP-specific error (e.g. connection refused)
		print('URL: {}, URLError: {}'.format(baseurl, e.reason))
	else:
		fileHandle = open(filename, "r", encoding = "utf8")
		soup = BeautifulSoup(fileHandle, 'html.parser')
		tables = soup.find_all(class_="table table-novels")
		for tab in tables:
			novels_dom = tab.find_all(class_="title")
			for title in novels_dom:
				name = title.find('a').string.replace('’', "'").strip()
				url = title.find('a').get('href')
				cursor.execute("SELECT NovelName,link,autor,cover FROM 'Information' WHERE NovelName LIKE ?", (name,))
				row = cursor.fetchone()
				if row is None:
					print('NEW', name)
					insert_novel(name, 'https://www.wuxiaworld.com'+url)
		fileHandle.close()
		os.remove(filename)
		
		filename = "./tmp/bdd_completed.html"
		baseurl = 'https://www.wuxiaworld.com/tag/completed'
		try:
			download(baseurl, filename)
		except HTTPError as e:
			# Return code error (e.g. 404, 501, ...)
			print('URL: {}, HTTPError: {} - {}'.format(baseurl, e.code, e.reason))
		except URLError as e:
			# Not an HTTP-specific error (e.g. connection refused)
			print('URL: {}, URLError: {}'.format(baseurl, e.reason))
		else:
			fileHandle = open(filename, "r", encoding = "utf8")
			soup = BeautifulSoup(fileHandle, 'html.parser')
			tab = soup.find(class_="media-list genres-list")
			novels_dom = tab.find_all(class_="media")
			for title in novels_dom:
				name = title.find('h4').string.replace('’', "'").strip()
				url = title.find('a').get('href')
				cursor.execute("SELECT NovelName,link,autor,cover FROM 'Information' WHERE NovelName LIKE ?", (name,))
				row = cursor.fetchone()
				if row is None:
					print('NEW', name)
					insert_novel(name, 'https://www.wuxiaworld.com'+url)
			fileHandle.close()
			os.remove(filename)
			
		
		print('Database Update Completed')

if __name__ == '__main__':
	start()
